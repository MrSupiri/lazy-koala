\section{Research Gap}

After a literature survey the author came to the conclusion finding a root cause of any failure within a distributed system is a very difficult issue due to it not having single output we can try to predict and most researchers have built their own simulation of a distributed system by themselves since there is not any open dataset about monitoring data mainly because it could contain sensitive information. 

Most currently established researches are done towards creating statistical models like clustering and linear regression. Even though these algorithms perform very well in small-scale systems, they struggle to keep up when the monitoring data become very noisy with scale. Another problem none of these papers properly  addressed was constant changes to services. Most published research considers target services as static, but in reality, these services can change even many times per day \citep{GoingtoM51:online}.

After talking with industry experts, the author concluded three main issues that all had with using a machine learning model as monitoring agent Reliability, Interpretability, and Tunability. On reliability, experts said that too many false positives will make operators lose faith in the system because it is gonna be another distraction to them. As operators have to make critical decisions with the output of these models, humans have been able to interpret it \citep{ribeiro2016should}. Finally, this system should act more like a tool rather than a replacement for human operators, because, no matter how sophisticated machine learning is, models cannot compete with the context a human can handle. 
