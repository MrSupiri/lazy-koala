\section{Research Motivation}

Modern distributed systems generates tons of useful and not so useful telemetry data. As system grows in demand and the size, these telemetry data only get more nosier and complex \textbf{add ref}. Its difficult for humans to make sense of all these data, especially if they don't have lot of years of experiences with the system. In the other hand, deep learning models thrives when it has tons of data to learn from. As these models can be trained on computer simulated environments they can learn concepts humans takes years to grasp within days (\cite{OpenAI_dota}, \cite{silver2017mastering}). Finally unlike humans a deep learning model can monitor a service 24x7 without taking any breaks which will not only prevent outage even before they happen, It could reduced \ac{mttr} because the issue can be detected way earlier than and human could do. 

