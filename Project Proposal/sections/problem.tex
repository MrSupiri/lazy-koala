\section{Problem Domain}

With the rise of cloud native applications \citep{CloudAdo16:online} a plethora of services to support these application came to play. Kubernetes it self is also tool develop to manage containerized microservices and it try solve most of the networking and service discovery challenges when it comes to containerized distributed systems.

As discussed in section \ref{monitoring-bg} monitoring is considered one of biggest challenges in microservices \citep{Understa56:online}. So to address this issue, 3 types of services were introduced. Log aggregators, distributed tracers and \ac{apm} systems. With that few companies started creating \ac{saas} products which integrate all 3 of these and show them under a single pane of glass. Some of the key players in this domain are Datadog, New Relic and Dynatrace to name a few from many. These works well for most part and lot of companies no matter the size depend on these services to handle their observability needs.

If we take Datadog as an example it offer a wide variety of futures from simple data collection to metric forecasts for predictive monitoring. If developers configured their services with Datadog agents correctly, Datadog will help it's users to visualize services performance from very high level and when a problems occurs it gives all the tools needs drill into the core and tally all the logs and performance and tracing data understand what's going on \citep{Datadog18:online}. They even has module called watchdog which does aggregate all the \acp{apm} data in background and try to find issues in them but currently only available as private beta.

Even though there are lot of great products available with all has few common issue, one of the main issue is it's up to developers to implement metric exports and tracing in their services. As a person who did his placement in small to medium size startup I first hand both managers and developers hesitate to spend time one things like these. Although platforms like Datadog support open initiatives like opentelemetry\footnote{\url{https://opentelemetry.io/}} to take the full power of these platforms services have to be architectured towards the observability platform that gonna get used, once committed it's very hard to migrate to another solution. Finally all these services require users to send over all of their key data including logs to get the most out of it and it could open up lot of security issues and privacy concerns down the road.

\section{Problem Definition}

One of the main problem in monitoring microservices is the sheer number of data it generate. It's humanly impossible to monitor the vitals of all the services and it's hard for single person understand the entire system. To overcome this \acp{sres} use abstracted metrics called \acp{sli} which measures the quality of the service in higher level. \acp{sli} will tell when there is issue in the system, but it's very hard to understand where the actual problem is from it along. To understand the root cause of the problem \acp{sres} need to dig into \acp{apm} of all the services and go though the logs of each of the troubling services.

When the system consists of 100s or 1000s of services which are inter depended it's really hard to find where the actual issue is coming from and it may require the attention from all the service owner's of failing services to go though the logs and \acp{apm} and identify the actual root cause of the failure.
This could greatly increase the \ac{mttr} and waste lot of developer time just looking at logs.

\subsection{Problem Statement}

Modern distributed systems are becoming big and complex so that one person can't understand the entire system. If there are lot of interconnected services, when a failure happens it will trigger lot of alerts from all effect services digging though all these alerts and uncovering the root cause of the problem could take a lot of time. Implementing a machine learning model which will watch over all the services and reacts to anomalies in real time could greatly reduce \ac{mttr} and improve developer experience when dealing with failure or a outage.
